<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>PyBayesOpt.jl Documentation · PyBayesOpt.jl</title><meta name="title" content="PyBayesOpt.jl Documentation · PyBayesOpt.jl"/><meta property="og:title" content="PyBayesOpt.jl Documentation · PyBayesOpt.jl"/><meta property="twitter:title" content="PyBayesOpt.jl Documentation · PyBayesOpt.jl"/><meta name="description" content="Documentation for PyBayesOpt.jl."/><meta property="og:description" content="Documentation for PyBayesOpt.jl."/><meta property="twitter:description" content="Documentation for PyBayesOpt.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>PyBayesOpt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>PyBayesOpt.jl Documentation</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#Benchmark-Functions"><span>Benchmark Functions</span></a></li><li><a class="tocitem" href="#Using-Optim.jl-Interface"><span>Using Optim.jl Interface</span></a></li><li><a class="tocitem" href="#Advanced-Usage"><span>Advanced Usage</span></a></li><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li><li><a class="tocitem" href="internal/">Internal API (Unexported)</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>PyBayesOpt.jl Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>PyBayesOpt.jl Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/j-fu/PyBayesOpt.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="PyBayesOpt.jl-Documentation"><a class="docs-heading-anchor" href="#PyBayesOpt.jl-Documentation">PyBayesOpt.jl Documentation</a><a id="PyBayesOpt.jl-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#PyBayesOpt.jl-Documentation" title="Permalink"></a></h1><p>Julia wrapper for Bayesian optimization tools available in Python.</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>PyBayesOpt.jl provides Julia interfaces to popular Python Bayesian optimization libraries:</p><ul><li><a href="https://github.com/bayesian-optimization/BayesianOptimization">BayesianOptimization</a> - A Python library for Bayesian optimization</li><li><a href="https://botorch.org/">BoTorch</a> - A Bayesian optimization library built on PyTorch for q-batch optimization</li></ul><p>The package implements the <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> interface for seamless integration with Julia&#39;s optimization ecosystem.</p><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><h3 id="Basic-BoTorch-Q-Batch-Optimization"><a class="docs-heading-anchor" href="#Basic-BoTorch-Q-Batch-Optimization">Basic BoTorch Q-Batch Optimization</a><a id="Basic-BoTorch-Q-Batch-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-BoTorch-Q-Batch-Optimization" title="Permalink"></a></h3><pre><code class="language-julia hljs">using PyBayesOpt
using Optim

# Define a test function to minimize
objective(x) = (x[1] - 2)^2 + (x[2] - 1)^2

# Set up optimization parameters
params = BoTorchQBatch(
    bounds = [-5.0 5.0; -5.0 5.0],  # [min max] for each dimension  
    nbatch = 4,     # batch size
    ninit = 10,     # initialization iterations
    nopt = 20       # optimization iterations
)

# Run optimization using Optim.jl interface
result = optimize(objective, params)

# Access results
println(&quot;Best point: &quot;, result.minimizer)
println(&quot;Best value: &quot;, result.minimum)
println(&quot;Function evaluations: &quot;, result.f_calls)</code></pre><h3 id="BayesianOptimization-Wrapper"><a class="docs-heading-anchor" href="#BayesianOptimization-Wrapper">BayesianOptimization Wrapper</a><a id="BayesianOptimization-Wrapper-1"></a><a class="docs-heading-anchor-permalink" href="#BayesianOptimization-Wrapper" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Using the BayesianOptimization wrapper
params = BayesianOptimization(
    bounds = [-5.0 5.0; -5.0 5.0],
    ninit = 10,
    nopt = 50
)

result = optimize(objective, params)</code></pre><h3 id="Interactive-Optimization-Loop"><a class="docs-heading-anchor" href="#Interactive-Optimization-Loop">Interactive Optimization Loop</a><a id="Interactive-Optimization-Loop-1"></a><a class="docs-heading-anchor-permalink" href="#Interactive-Optimization-Loop" title="Permalink"></a></h3><p>For more control over the optimization process:</p><pre><code class="language-julia hljs"># Interactive optimization with BoTorch
state = BoTorchQBatchState(params=BoTorchQBatch(bounds=[-5.0 5.0; -5.0 5.0]))

while !finished(state)
    # Get next batch of points to evaluate
    pts = ask!(state)
    
    # Evaluate function (can be parallelized)
    values = [objective(pts[:, i]) for i in 1:size(pts, 2)]
    
    # Provide results back to optimizer
    tell!(state, pts, values)
    
    # Check current best
    if state.optimization_complete
        best_pt, best_val = bestpoint(state)
        println(&quot;Current best: $best_pt -&gt; $best_val&quot;)
    end
end</code></pre><h2 id="Benchmark-Functions"><a class="docs-heading-anchor" href="#Benchmark-Functions">Benchmark Functions</a><a id="Benchmark-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmark-Functions" title="Permalink"></a></h2><p>The package includes several standard optimization benchmarks:</p><pre><code class="language-julia hljs"># Use benchmark functions
branin = BraninFunction()
result = optimize(branin, BoTorchQBatch(bounds=branin.bounds))

ackley = AckleyFunction(dim=3)  # 3D Ackley function
result = optimize(ackley, BoTorchQBatch(bounds=ackley.bounds))

rosenbrock = RosenbrockFunction(dim=2)
result = optimize(rosenbrock, BoTorchQBatch(bounds=rosenbrock.bounds))</code></pre><h2 id="Using-Optim.jl-Interface"><a class="docs-heading-anchor" href="#Using-Optim.jl-Interface">Using Optim.jl Interface</a><a id="Using-Optim.jl-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Using-Optim.jl-Interface" title="Permalink"></a></h2><p>PyBayesOpt implements the Optim.jl <code>optimize</code> function interface, making it a drop-in replacement for other Optim.jl optimizers:</p><pre><code class="language-julia hljs">using Optim
using PyBayesOpt

# Your objective function
function objective(x)
    return sum((x .- [2.0, 3.0]).^2)  # minimize at [2.0, 3.0]
end

# Create method instance
method = BoTorchQBatch(
    bounds = [0.0 5.0; 0.0 5.0],
    nbatch = 2,
    ninit = 8,
    nopt = 15,
    acqmethod = :qEI
)

# Use with Optim.optimize
result = Optim.optimize(objective, method)

# Standard Optim.jl result interface
println(&quot;Minimizer: &quot;, Optim.minimizer(result))
println(&quot;Minimum: &quot;, Optim.minimum(result))
println(&quot;F calls: &quot;, Optim.f_calls(result))

# Additional methods from BoTorch
if isa(result, BoTorchQBatchState)
    # Evaluate posterior at any point
    mean, var = evalposterior(result, [2.0, 3.0])
    println(&quot;Posterior at [2,3]: mean=$mean, variance=$var&quot;)
    
    # Sample from posterior maximum distribution
    max_point, std_dev = sampleposteriormin(result, nsamples=1000)
    println(&quot;Estimated maximum: $max_point ± $std_dev&quot;)
end</code></pre><h2 id="Advanced-Usage"><a class="docs-heading-anchor" href="#Advanced-Usage">Advanced Usage</a><a id="Advanced-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Usage" title="Permalink"></a></h2><h3 id="Acquisition-Functions"><a class="docs-heading-anchor" href="#Acquisition-Functions">Acquisition Functions</a><a id="Acquisition-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Acquisition-Functions" title="Permalink"></a></h3><p>BoTorch supports various acquisition functions:</p><pre><code class="language-julia hljs">method = BoTorchQBatch(
    acqmethod = :qLogEI,  # Options: :qEI, :qNEI, :qLogEI, :qLogNEI, :qUCB, :qPI
    qUCB_beta = 2.5       # Only used for :qUCB
)</code></pre><h3 id="Parallel-Evaluation"><a class="docs-heading-anchor" href="#Parallel-Evaluation">Parallel Evaluation</a><a id="Parallel-Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-Evaluation" title="Permalink"></a></h3><p>The q-batch approach naturally supports parallel function evaluation:</p><pre><code class="language-julia hljs">using Distributed
addprocs(4)  # Add 4 worker processes

@everywhere using PyBayesOpt

function parallel_eval(objective, state)
    while !finished(state)
        pts = ask!(state)
        
        # Parallel evaluation using pmap
        values = pmap(i -&gt; objective(pts[:, i]), 1:size(pts, 2))
        
        tell!(state, pts, values)
    end
    return state
end

result = parallel_eval(objective, BoTorchQBatchState(params=method))</code></pre><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt" href="#PyBayesOpt"><code>PyBayesOpt</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PyBayesOpt</code></pre><p><a href="https://github.com/j-fu/PyBayesOpt.jl/actions/workflows/CI.yml"><img src="https://github.com/j-fu/PyBayesOpt.jl/actions/workflows/CI.yml/badge.svg" alt/></a> <a href="https://j-fu.github.io/PyBayesOpt.jl/stable"><img src="https://img.shields.io/badge/docs-stable-blue.svg" alt/></a> <a href="https://j-fu.github.io/PyBayesOpt.jl/dev"><img src="https://img.shields.io/badge/docs-dev-blue.svg" alt/></a></p><p><strong>PyBayesOpt.jl</strong></p><p>Julia wrapper to some Bayesian optimization tools available in Python:</p><ul><li><a href="https://github.com/bayesian-optimization/BayesianOptimization">BayesianOptimization</a> aka <a href="https://bayesian-optimization.github.io/BayesianOptimization/3.1.0/reference/bayes_opt.html">bayes_opt</a> or <a href="https://pypi.org/project/bayesian-optimization/">bayesian-optimization</a> </li><li>A q-batch  Bayesian optimizer implemented using <a href="https://botorch.org/">BoTorch</a></li></ul><p>It uses a very partial implementation of the optimizer interface provided by <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a>.</p><p><strong>Installation</strong></p><p><strong>Python prerequisites</strong></p><p>The package uses PyCall.jl to access the python code, and therefore requires a python installation which is working well with this package. See <a href="requirements.txt">requirements.txt</a> for the python packages to be installed.</p><pre><code class="language-bash hljs">pip install -r requirements.txt</code></pre><p>If you use this under linux, you may have to set the environment variable <code>TORCH_USE_RTLD_GLOBAL=1</code> in order to avoid some loading problems with the mkl library:</p><pre><code class="language-bash hljs">export TORCH_USE_RTLD_GLOBAL=1</code></pre><p><strong>Installation via PackageNursery registry</strong></p><p>The package can be installed with the Julia package manager in a standard way For the time being, it is registered in the julia package registry <a href="https://github.com/j-fu/PackageNursery">https://github.com/j-fu/PackageNursery</a> To add the registry (needed only once), and to install the package,  from the Julia REPL, type <code>]</code> to enter the Pkg REPL mode and run:</p><pre><code class="nohighlight hljs">pkg&gt; registry add https://github.com/j-fu/PackageNursery</code></pre><p>Please be aware that adding a registry to your Julia installation requires to trust the registry maintainer for handling things in a correct way. In particular, the registry should not register higher versions of packages which are already registered in the Julia General Registry. One can check this by visiting the above mentionend github repository URL and inspecting the contents.</p><p><strong>Installation via  repository URL</strong></p><pre><code class="language-julia hljs">using Pkg
Pkg.add(url=&quot;https://github.com/j-fu/PyBayesOpt.jl&quot;)</code></pre><p><strong>Quick Start</strong></p><p><strong>Basic Usage with Optim.jl Interface</strong></p><pre><code class="language-julia hljs">using PyBayesOpt
using Optim

# Define a function to minimize
f(x) = (x[1] - 2.0)^2 + (x[2] - 1.0)^2

# Create optimizer - BoTorch q-batch is recommended
method = BoTorchQBatch(
    bounds = [0.0 4.0; -1.0 3.0],  # [min max] for each dimension
    nbatch = 4,      # evaluate 4 points per iteration
    ninit = 10,      # 10 initialization iterations  
    nopt = 15        # 15 optimization iterations
)

# Optimize using standard Optim.jl interface
result = optimize(f, method)

# Access results
println(&quot;Best point: &quot;, result.minimizer)    # [2.0, 1.0]
println(&quot;Best value: &quot;, result.minimum)      # ≈ 0.0
println(&quot;Evaluations: &quot;, result.f_calls)     # 100 total evaluations</code></pre><p><strong>Interactive Optimization Loop</strong></p><p>For maximum control over the optimization process:</p><pre><code class="language-julia hljs">state = BoTorchQBatchState(params=method)

while !finished(state)
    # Get next batch of points to evaluate
    candidates = ask!(state)
    
    # Evaluate function (can be parallelized)  
    values = [f(candidates[:, i]) for i in 1:size(candidates, 2)]
    
    # Provide results back to optimizer
    tell!(state, candidates, values)
end

# Final result
best_point, best_value = bestpoint(state)</code></pre><p><strong>Using Benchmark Functions</strong></p><pre><code class="language-julia hljs"># Built-in benchmark functions
branin = BraninFunction()
result = optimize(branin, BoTorchQBatch(bounds=branin.bounds))

ackley = AckleyFunction(dim=5)  # 5-dimensional
result = optimize(ackley, BoTorchQBatch(bounds=ackley.bounds))</code></pre><p><strong>Features</strong></p><p><strong>Acquisition Functions</strong></p><p>BoTorch supports multiple acquisition functions:</p><ul><li><code>:qEI</code> / <code>:qExpectedImprovement</code> - Expected Improvement</li><li><code>:qLogEI</code> / <code>:qLogExpectedImprovement</code> - Log Expected Improvement (recommended)</li><li><code>:qNEI</code> / <code>:qNoisyExpectedImprovement</code> - Noisy Expected Improvement</li><li><code>:qLogNEI</code> / <code>:qLogNoisyExpectedImprovement</code> - Log Noisy Expected Improvement  </li><li><code>:qUCB</code> / <code>:qUpperConfidenceBound</code> - Upper Confidence Bound</li><li><code>:qPI</code> / <code>:qProbabilityOfImprovement</code> - Probability of Improvement</li></ul><p><strong>Parallel Evaluation</strong></p><p>The q-batch approach naturally supports parallel function evaluation:</p><pre><code class="language-julia hljs">using Base.Threads

# In the optimization loop:
values = zeros(nbatch)
@threads for i in 1:nbatch
    values[i] = expensive_function(candidates[:, i])
end</code></pre><p><strong>Posterior Analysis</strong></p><p>After optimization, you can analyze the Gaussian process posterior:</p><pre><code class="language-julia hljs"># Evaluate posterior at any point
mean, variance = evalposterior(result, [1.0, 2.0])

# Sample from posterior maximum distribution
max_point, std_dev = samplemaxpost(result, nsamples=1000)
println(&quot;Estimated global optimum: $max_point ± $std_dev&quot;)</code></pre><p><strong>Optimizers</strong></p><p><strong>BoTorchQBatch (Recommended)</strong></p><p>Advanced q-batch Bayesian optimization using BoTorch:</p><pre><code class="language-julia hljs">BoTorchQBatch(
    bounds = [-1.0 1.0; -1.0 1.0],    # Optimization bounds
    nbatch = 4,                        # Batch size
    ninit = 10,                        # Initialization iterations
    nopt = 20,                         # Optimization iterations  
    acqmethod = :qLogEI,               # Acquisition function
    seed = 1234,                       # Random seed
    verbose = true,                    # Print progress
    acq_nrestarts = 20,                # Acquisition optimization restarts
    acq_nsamples = 512,                # Raw samples for acquisition optimization
    qUCB_beta = 2.0                    # Beta parameter for qUCB
)</code></pre><p><strong>BayesianOptimization</strong></p><p>Classical Bayesian optimization wrapper:</p><pre><code class="language-julia hljs">BayesianOptimization(
    bounds = [-1.0 1.0; -1.0 1.0],    # Optimization bounds
    ninit = 10,                        # Initial random samples
    nopt = 50,                         # Optimization iterations
    verbose = 0,                       # Verbosity level
    seed = 1                           # Random seed
)</code></pre><p><strong>Examples</strong></p><p>See the <code>examples/</code> directory for:</p><ul><li><code>quick_start.jl</code> - Basic usage examples  </li><li><code>optim_interface_example.jl</code> - Comprehensive Optim.jl interface demo</li></ul><p><strong>AI usage statement</strong></p><p>Github copilot with Claude Sonnet 4 and GPT-5 was used to design an initial python version of the BoTorch based algorithm, and to brush up documentation and testing infrastructure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.BoTorchQBatch" href="#PyBayesOpt.BoTorchQBatch"><code>PyBayesOpt.BoTorchQBatch</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">struct BoTorchQBatch</code></pre><p>Struct describing optimization for BoTorch based q-batch Bayesian optimization</p><p><strong>Fields:</strong></p><ul><li><p><code>bounds::Matrix{Float64} = [-1 1]&#39;</code> : <code>ndim x 2</code> matrix of evaluation bounds</p></li><li><p><code>nbatch::Int = 1</code>: batch size for evaluations of black box model</p></li><li><p><code>ninit::Int = 10</code>: number of initialization iterations resulting in <code>nbatch*ninit</code> evaluations</p></li><li><p><code>nopt::Int = 10</code>: number of optimization iterations resulting in <code>nbatch*nopt</code> evaluations</p></li><li><p><code>acqmethod::Symbol = :qLogEI</code>: acquisition method.  </p><p>Valid metods (see <a href="https://botorch.readthedocs.io/en/stable/acquisition.html">BoTorch docmentation</a>):</p><ul><li><code>:qEI</code>, <code>:qExpectedImprovement</code></li><li><code>:qNEI</code>, <code>:qNoisyExpectedImprovement</code></li><li><code>:qLogEI</code>, <code>:qLogExpectedImprovement</code></li><li><code>:qLogNEI</code>, <code>:qLogNoisyExpetedImprovement</code></li><li><code>:qUCB</code>, <code>:qUpperConfidenceBound</code></li><li><code>:qPI</code>, <code>:qProbabilityOfImprovement</code></li></ul></li><li><p><code>seed::Int = 1234</code>: random seed</p></li><li><p><code>verbose::Bool = true</code>: verbosity</p></li><li><p><code>acq_nrestarts::Int = 20</code>: <code>num_restarts</code> parameter in <code>optimize_acqf</code></p></li><li><p><code>acq_nsamples::Int = 512</code>: <code>raw_samples</code> parameter in  <code>optimize_acqf</code></p></li><li><p><code>qUCB_beta::Float64 = 2.0</code>: beta parameter for qUCB_beta acquisition method</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.BoTorchQBatchState" href="#PyBayesOpt.BoTorchQBatchState"><code>PyBayesOpt.BoTorchQBatchState</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">struct BoTorchQBatchState</code></pre><p>State for  <a href="#PyBayesOpt.BoTorchQBatch"><code>BoTorchQBatch</code></a>, also used as result struct.</p><p>An instance of this state can be used either as the method paramer for the <code>optimize</code> function, or in  user implemented loop as seen below:</p><pre><code class="nohighlight hljs">state = BoTorchQBatchState(; params)
while !finished(state)
    pts = ask!(state)
    values = zeros(state.params.nbatch)
    Threads.@threads for i in 1:size(pts, 2)
          values[i] = func(pts[:, i])
    end
    tell!(state, pts, values)
end</code></pre><p><strong>Fields</strong></p><ul><li><code>X_ini::Union{Nothing, Matrix{Float64}} = nothing</code>: initialization points</li><li><code>X_obs::Union{Nothing, PyObject} = nothing</code>: training points</li><li><code>Y_obs::Union{Nothing, PyObject} = nothing</code>: training values</li><li><code>gpmodel::Union{Nothing, PyObject} = nothing</code>: Gaussian process model</li><li><code>evaluations_used::Int = 0</code>: number of evaluations done</li><li><code>initialization_complete::Bool = false</code>: flag indicating initialization state</li><li><code>optimization_complete::Bool = false</code>: flag indicating optimization state</li><li><code>init_iterations_done::Int = 0</code>: initial iterations performed</li><li><code>optim_iterations_done::Int = 0</code>: optimization iterations performed</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.BayesianOptimization" href="#PyBayesOpt.BayesianOptimization"><code>PyBayesOpt.BayesianOptimization</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">struct BayesianOptimization</code></pre><p>Optimizer wrapping  <a href="https://github.com/bayesian-optimization/BayesianOptimization">BayesianOptimization</a>.</p><p><strong>Fields:</strong></p><ul><li>&#39;bounds::Matrix{Float64}&#39;</li><li>&#39;ninit::Int = 10&#39;</li><li>&#39;nopt::Int = 100&#39;</li><li>&#39;verbose::Int = 0&#39;</li><li>&#39;seed::Int = 1&#39;</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Optim.optimize" href="#Optim.optimize"><code>Optim.optimize</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Optim.optimize(func, params::BoTorchQBatch)</code></pre><p>Minimize black-box function <code>func</code> using the <a href="#PyBayesOpt.BoTorchQBatch"><code>BoTorchQBatch</code></a> Bayesian optimization method.</p><p>This provides an <code>Optim.jl</code>-compatible interface so you can call <code>optimize(func, method)</code> or <code>Optim.optimize(func, method)</code> directly. The optimization proceeds in two phases:</p><ol><li>Initialization: <code>params.ninit</code> batches of random (Sobol) points are evaluated.</li><li>Optimization: <code>params.nopt</code> iterations of model-based batch acquisition optimization.</li></ol><p>Multi-threading: If <code>Threads.nthreads() &gt; 1</code>, function evaluations within a batch are threaded.</p><p>Arguments</p><ul><li><code>func::Function</code>: Objective to minimize (should accept a vector of reals and return a scalar).</li><li><code>params::BoTorchQBatch</code>: Configuration object.</li></ul><p>Returns</p><ul><li><code>BoTorchQBatchState</code>: Final state which behaves like an <code>Optim.MultivariateOptimizationResults</code> object (supports <code>minimum</code>, <code>minimizer</code>, <code>f_calls</code>, etc.).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section><section><div><pre><code class="language-julia hljs">Optim.optimize(f, params::BayesianOptimization)</code></pre><p>Minimize black-box function <code>f</code> using the Python <code>BayesianOptimization</code> library via the <a href="#PyBayesOpt.BayesianOptimization"><code>BayesianOptimization</code></a> parameter struct.</p><p>Workflow</p><ol><li>Construct bounds dictionary.</li><li>Wrap objective as a maximization target (the Python library maximizes) by negating.</li><li>Run random initialization (<code>ninit</code>) followed by model-guided iterations (<code>nopt</code>).</li><li>Convert best (max) record back to a minimization result.</li></ol><p>Returns a <code>BayesianOptimizationResult</code> with <code>minimum</code>, <code>minimizer</code>, and bookkeeping fields.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.summary" href="#Base.summary"><code>Base.summary</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Optim.summary(state::BoTorchQBatchState)</code></pre><p>Print a concise human-readable summary of a <a href="#PyBayesOpt.BoTorchQBatchState"><code>BoTorchQBatchState</code></a> including phase, current best point, best value, and (once optimization is complete) posterior statistics at the incumbent.</p><p>Intended mainly for verbose / debugging output; called automatically when <code>params.verbose=true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.initializing" href="#PyBayesOpt.initializing"><code>PyBayesOpt.initializing</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>initializing(qbatch_state)</p><p>Tell if optimization is in initialization state.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.optimizing" href="#PyBayesOpt.optimizing"><code>PyBayesOpt.optimizing</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>optimizing(qbatch_state)</p><p>Tell if optimization is in optimization loop.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.finished" href="#PyBayesOpt.finished"><code>PyBayesOpt.finished</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>finished(qbatch_state)</p><p>Tell if optimization is finished</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.ask!" href="#PyBayesOpt.ask!"><code>PyBayesOpt.ask!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ask!(qbatch_state)</code></pre><p>Ask for a new batch of points to be avaluated. Returns <code>dim x batchsize</code> matrix. At once may generate intial candidates or optimize the acquisition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.tell!" href="#PyBayesOpt.tell!"><code>PyBayesOpt.tell!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">tell!(qbatch_state, candidates, valus)</code></pre><p>Provide newly evaluated candidate points to the optimizatio, update the initialization resp. training set.    </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.bestpoint" href="#PyBayesOpt.bestpoint"><code>PyBayesOpt.bestpoint</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bestpoint(qbatch_state)</code></pre><p>Return the best point and function value from the observation set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.evalposterior" href="#PyBayesOpt.evalposterior"><code>PyBayesOpt.evalposterior</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">evalposterior(qbatch_state, point)</code></pre><p>Evaluate posterior at given point. Returns posterior mean and variance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.sampleposteriormin" href="#PyBayesOpt.sampleposteriormin"><code>PyBayesOpt.sampleposteriormin</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sampleposteriormin(qbatch_state; nsamples)</code></pre><p>Sample the posterior minimum using  <a href="https://botorch.readthedocs.io/en/stable/generation.html#botorch.generation.sampling.MaxPosteriorSampling">MaxPosteriorSampling</a>.</p><p>Returns the estimated minimum point and the estimated standard deviation of its coordinates. Use <a href="#PyBayesOpt.evalposterior"><code>evalposterior</code></a> to obtain the function value in that point.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.BayesianOptimizationResult" href="#PyBayesOpt.BayesianOptimizationResult"><code>PyBayesOpt.BayesianOptimizationResult</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">struct BayesianOptimizationResult &lt;: Optim.OptimizationResults</code></pre><p>Result struct for <a href="#PyBayesOpt.BayesianOptimization"><code>BayesianOptimization</code></a>, compatible with Optim.jl interface.</p><p><strong>Fields</strong></p><ul><li><code>params::BayesianOptimization</code>: The optimization parameters used</li><li><code>f_calls::Int</code>: Number of function evaluations performed</li><li><code>minimizer::Vector{Float64}</code>: The best point found</li><li><code>minimum::Float64</code>: The best function value found</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.AbstractBenchmarkFunction" href="#PyBayesOpt.AbstractBenchmarkFunction"><code>PyBayesOpt.AbstractBenchmarkFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractBenchmarkFunction</code></pre><p>Abstract base type for benchmark optimization functions.</p><p>All benchmark functions should implement:</p><ul><li>Function call syntax <code>f(x)</code> where <code>x</code> is a vector</li><li>Fields <code>bounds</code>, <code>optimal_value</code>, and optionally <code>optimal_point</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.SimpleFunction" href="#PyBayesOpt.SimpleFunction"><code>PyBayesOpt.SimpleFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimpleFunction &lt;: AbstractBenchmarkFunction</code></pre><p>A simple quadratic test function for optimization benchmarking.</p><p>Function: <code>f(x) = x[1]² + (x[2] - 1)² - 1</code></p><p><strong>Fields</strong></p><ul><li><code>bounds::Matrix{Float64}</code>: Optimization bounds <code>[[-10 10]; [-10 10]]</code></li><li><code>optimal_value::Float64</code>: Known optimal value <code>-1.0</code></li><li><code>optimal_point::Vector{Float64}</code>: Known optimal point <code>[0.0, 1.0]</code></li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">simple_func = SimpleFunction()
result = optimize(simple_func, BoTorchQBatch(bounds=simple_func.bounds))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.BraninFunction" href="#PyBayesOpt.BraninFunction"><code>PyBayesOpt.BraninFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BraninFunction &lt;: AbstractBenchmarkFunction</code></pre><p>The Branin function - a common benchmark for global optimization.</p><p>Function: <code>f(x₁,x₂) = a(x₂ - bx₁² + cx₁ - r)² + s(1-t)cos(x₁) + s</code> where <code>a=1, b=5.1/(4π²), c=5/π, r=6, s=10, t=1/(8π)</code></p><p><strong>Fields</strong></p><ul><li><code>bounds::Matrix{Float64}</code>: Optimization bounds <code>[[-5 10]; [0 15]]</code></li><li><code>optimal_value::Float64</code>: Global minimum value <code>0.397887</code></li></ul><p>The function has 3 global minima at approximately:</p><ul><li><code>(-π, 12.275)</code>, <code>(π, 2.275)</code>, <code>(9.42478, 2.475)</code></li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">branin_func = BraninFunction()
result = optimize(branin_func, BoTorchQBatch(bounds=branin_func.bounds))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.AckleyFunction" href="#PyBayesOpt.AckleyFunction"><code>PyBayesOpt.AckleyFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AckleyFunction &lt;: AbstractBenchmarkFunction</code></pre><p>The Ackley function - a widely used benchmark function for global optimization.</p><p>Function: <code>f(x) = -a·exp(-b·√(1/d·∑xᵢ²)) - exp(1/d·∑cos(c·xᵢ)) + a + e</code> where typically <code>a=20, b=0.2, c=2π</code></p><p><strong>Fields</strong></p><ul><li><code>dim::Int</code>: Problem dimension (default: 2)  </li><li><code>bounds::Matrix{Float64}</code>: Optimization bounds (default: <code>[-32.768, 32.768]</code> for each dimension)</li><li><code>optimal_value::Float64</code>: Global minimum value <code>0.0</code></li><li><code>optimal_point::Vector{Float64}</code>: Global minimum at origin</li></ul><p>The function has a global minimum at the origin with many local minima.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">ackley_func = AckleyFunction(dim=5)  # 5-dimensional Ackley function
result = optimize(ackley_func, BoTorchQBatch(bounds=ackley_func.bounds))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PyBayesOpt.RosenbrockFunction" href="#PyBayesOpt.RosenbrockFunction"><code>PyBayesOpt.RosenbrockFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RosenbrockFunction &lt;: AbstractBenchmarkFunction</code></pre><p>The Rosenbrock function (also known as &quot;Rosenbrock&#39;s valley&quot; or &quot;banana function&quot;).</p><p>Function: <code>f(x) = ∑[100(xᵢ₊₁ - xᵢ²)² + (1 - xᵢ)²]</code> for i=1 to n-1</p><p><strong>Fields</strong></p><ul><li><code>dim::Int</code>: Problem dimension (default: 2)</li><li><code>bounds::Matrix{Float64}</code>: Optimization bounds (default: <code>[-5, 10]</code> for each dimension)  </li><li><code>optimal_value::Float64</code>: Global minimum value <code>0.0</code></li><li><code>optimal_point::Vector{Float64}</code>: Global minimum at <code>ones(dim)</code></li></ul><p>The function has a global minimum in a narrow, curved valley making it challenging for optimization algorithms.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">rosenbrock_func = RosenbrockFunction(dim=3)  # 3-dimensional Rosenbrock function
result = optimize(rosenbrock_func, BoTorchQBatch(bounds=rosenbrock_func.bounds))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/j-fu/PyBayesOpt.jl">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="internal/">Internal API (Unexported) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 20 September 2025 00:06">Saturday 20 September 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
